<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://jzq6520.github.io</id>
    <title>chuck</title>
    <updated>2019-10-17T02:46:28.027Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://jzq6520.github.io"/>
    <link rel="self" href="https://jzq6520.github.io/atom.xml"/>
    <subtitle>天地不仁以万物为刍狗</subtitle>
    <logo>https://jzq6520.github.io/images/avatar.png</logo>
    <icon>https://jzq6520.github.io/favicon.ico</icon>
    <rights>All rights reserved 2019, chuck</rights>
    <entry>
        <title type="html"><![CDATA[cv-笔记-主动学习active learning的思想]]></title>
        <id>https://jzq6520.github.io/post/cv-bi-ji-zhu-dong-xue-xi-active-learning</id>
        <link href="https://jzq6520.github.io/post/cv-bi-ji-zhu-dong-xue-xi-active-learning">
        </link>
        <updated>2019-10-17T02:27:00.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li><strong>主动学习通过一定的算法查询最有用的未标记样本，并交由专家进行标记，然后用查询到的样本训练分类模型来提高模型的精确度。</strong></li>
<li>那么被动学习就是说别人标注了什么数据我们就拿什么数据进行训练，而不是主动的去挖掘一些模型需要的数据去标注。</li>
<li>查询函数（就是从未标注数据中挖掘需要进行标注的数据的方法）的设计最常用的策略是：不确定性准则（uncertainty）和差异性准则（diversity）。</li>
</ul>
<p>其实最简单的做法就是选择出模型预测误差较大的数据进行标注。
<img src="https://jzq6520.github.io/post-images/1571280110452.png" alt=""></p>
<h2 id="引用">引用</h2>
<ul>
<li>https://www.cnblogs.com/hust-yingjie/p/8522165.html</li>
<li>https://www.jianshu.com/p/e908c3595fc0</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CV-笔记-深度学习模型压缩]]></title>
        <id>https://jzq6520.github.io/post/cv-bi-ji-shen-du-xue-xi-mo-xing-ya-suo</id>
        <link href="https://jzq6520.github.io/post/cv-bi-ji-shen-du-xue-xi-mo-xing-ya-suo">
        </link>
        <updated>2019-10-11T09:03:34.000Z</updated>
        <content type="html"><![CDATA[<p>在不降低或者是不大幅度减少精度的条件下，目前的模型压缩方式有：</p>
<ul>
<li>知识蒸馏；</li>
<li>量化</li>
<li>稀疏</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CV-笔记-图像质量评价Image quality assessment IQA简介]]></title>
        <id>https://jzq6520.github.io/post/cv-bi-ji-tu-xiang-zhi-liang-ping-jie-image-quality-assessment-iqa-jian-jie</id>
        <link href="https://jzq6520.github.io/post/cv-bi-ji-tu-xiang-zhi-liang-ping-jie-image-quality-assessment-iqa-jian-jie">
        </link>
        <updated>2019-10-10T02:32:14.000Z</updated>
        <content type="html"><![CDATA[<p>2019年10月10日</p>
<h2 id="1-简介">1 简介</h2>
<p>图像质量评价（Image quality assessment，IQA）按照是否有参考图像可以分为三种：1. 有参IQA，2.半参IQA，3. 无参IQA。</p>
<p>有参图像质量评价虽然效果很好，但是前提是要有一个参考图像，也就是说一张质量好的图像作为参考，然后给评价的图像进行打分，而且参考图像和被打分的图像是要同一个图。但是在某些场景下参考图像是比较难获得的。</p>
<p>在测试图像压缩、图像传输效果时候或许可以有一个原始图像作为参考，然后测试被压缩或被传输后的图像知道。但是在很多场景是无法获得参考图像的，例如你拍摄一张图像，如果你没有拍摄一个绝对清晰的图像，那就无法拿到参考图像。比还有一些实时的场景下我们是不好获得参考图像的。</p>
<p><strong>所以这时候无参图像质量评价就出来了。</strong></p>
<h2 id="2-基于深度学习的图像质量评价">2 基于深度学习的图像质量评价</h2>
<p>废话不多说直接进入正题，这里我们主要讨论利用深度学习来解决图像质量评价问题。传统方法可以自行谷歌。</p>
<p>在我看来基于深度学习的图像质量评价主要有两种：</p>
<ol>
<li>直接利用回归，输入为图像，输出为质量评价分数。那么训练数据集就是 图像和label。</li>
<li>利用伪参考图像，然后将待评价图像和伪参考图像一起输入到回归网络中，输出质量评价分数。那么训练数据要包含：待评价图像、参考图像和label。注：伪参考图像这个说法是我自己想的。</li>
</ol>
<p>接下来对这两种基于深度学习的方法进行简单介绍，并且附上论文。</p>
<h2 id="21-直接利用回归">2.1 直接利用回归</h2>
<p>直接利用回归进行质量评价。这个思路比较简单，就是我们输入一张待评价图像然后输出的是一个值（score）。</p>
<p>网络就可以设计为一个卷积神经网络，例如我们可以选用VGG网络进行回归。</p>
<p><strong>但是由于图像质量评价的数据往往难以获得，且存在很大的主观性，所以说数据量是不大的。所以Xialei Liu等人就提出了RankIQA来解决数据量小的问题。</strong></p>
<h3 id="211-rankiqa">2.1.1 RankIQA</h3>
<p>别看名字这么玄乎，其实本身思想其实很简单，就是利用迁移学习。那么从哪里迁移网络参数呢？是从参数共享的网络得到。<strong>这个参数共享又不能说是孪生网络（注：论文中说是孪生网络），因为这个网络不像孪生网络一样有连接在一块，所以应该只能算是参数共享的网络</strong>。</p>
<p>首先构建两个参数共享的网络，这时候将两张图分别从两个网络输入，网络输出的是一个质量评价分数，这时候我们是知道两张输入图像哪张好哪张坏的，所以这时候就可以比较两个网络输出的质量评价分数来进行计算loss。如果输出的质量评价分数的大小关系和实际一样，那么就不计算loss。</p>
<p><img src="https://jzq6520.github.io/post-images/1570677420978.png" alt=""></p>
<p>那么输入的图像是哪里来的呢？是我们自己构造的，利用高斯核对图像进行模糊，这样我们就可以生成一组不同模糊程度的图像。因为我们不知道模糊程度该打几分，所以在训练参数共享网络的时候，loss是通过比较两个网络的数据来进行计算的，而不是和传统的一样计算均方差。</p>
<p>LOSS:
<img src="https://jzq6520.github.io/post-images/1570677513453.png" alt=""></p>
<p>这里有个假设，就是x1是大于x2的，所以从这个公式1的Loss公式可以看出，当网络输出x1大于x2时不计算loss，反之则计算一个loss。</p>
<p>最后，由于我们自己生成了许多可以指定图像质量相对好坏的数据，所以可以训练更深的网络，克服了一部分数据量的问题。然后利用在人工标注的groundtruth上进行finetune（微调）得到最终的回归网络（质量评价网络）。</p>
<p><strong>总结：数据上只需要图像和对应的质量分数，网络相对简单。利用了迁移学习和很聪明的学习技巧和损失函数</strong></p>
<h2 id="22-利用伪参考图像">2.2  利用伪参考图像</h2>
<p>为什么我说这个是伪参考图像，因为这里面<strong>训练的时候是需要参考图像</strong>的，并且<strong>网络会生成一个假的参考图像</strong>，这个参考图像是通过网络对质量差的图像<strong>修复得到</strong>，例如一种模糊图像，然后由网络对其进行修复生成一张清晰的图像。然后利用这个清晰的图像作为参考图像对图像进行质量评价。</p>
<p>这里介绍两篇文章：RAN4IQA和Hallucinated-IQA，这两篇文章都是这样的思路，都是利用GAN（对抗生成网络）修复质量差的图像，然后将得到的修复后的图像（伪参考图像）作为参考图像对待评价图像进行打分。</p>
<p>所以这两个网络可以分解成三部分：<strong>伪参考图像评价网络 = GAN + 评价网络 = 修复网络（生成网络）+ 判别网络 + 评价网络</strong></p>
<p><strong>其实我们可以发现，当我们抛开评价网络，剩下的GAN就成了一个图像修复网络了</strong>。</p>
<p>再说一下这两个网络的区别：</p>
<ul>
<li>RAN4IQA是将修复后的图像和待参考图像输入到<strong>孪生网络</strong>中去回归得到分数。当然这里是基于patch的，所以还会有一个patch的权重，最后将所有patch的权重加权平均得到最后整张图像的分数。</li>
<li>Hallucinated-IQA是将<strong>差值图像</strong>（修复后的和待评价图像相减后得到的图）和待参考图像输入到一个<strong>双输入网络</strong>中，回归得到一个分数。并且使用了修复网络的下采样输出的特征。</li>
</ul>
<h3 id="221-ran4iqa">2.2.1 RAN4IQA</h3>
<p><img src="https://jzq6520.github.io/post-images/1570678849786.png" alt=""></p>
<h3 id="222-hallucinated-iqa">2.2.2 Hallucinated-IQA</h3>
<p><img src="https://jzq6520.github.io/post-images/1570678886713.png" alt=""></p>
<h2 id="3-总结">3 总结</h2>
<p>当有参考图像的时候可以训练一个伪参考图像网络，当没有参考图像的时候可以训练一个RankIQA网络。</p>
<h2 id="4-参考">4 参考</h2>
<ul>
<li>Hallucinated-IQA: No-Reference Image Quality Assessment via Adversarial Learning</li>
<li>RAN4IQA: Restorative Adversarial Nets for No-Reference Image Quality Assessment</li>
<li>RankIQA: Learning from Rankings for No-reference Image Quality Assessment</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[keras-Callback回调函数]]></title>
        <id>https://jzq6520.github.io/post/keras-callback-hui-diao-han-shu</id>
        <link href="https://jzq6520.github.io/post/keras-callback-hui-diao-han-shu">
        </link>
        <updated>2019-07-29T06:30:07.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1-回调函数的定义">1 回调函数的定义</h2>
<p>当程序跑起来时，一般情况下，应用程序（application program）会时常通过API调用库里所预先备好的函数。但是有些库函数（library function）却要求应用先传给它一个函数，好在合适的时候调用，以完成目标任务。这个被传入的、后又被调用的函数就称为回调函数（callback function）。</p>
<h4 id="回调函数的例子">回调函数的例子</h4>
<pre><code class="language-python">### 回调函数
#回调函数1
#生成一个2k形式的偶数
def double(x):
    return x * 2
    
#回调函数2
#生成一个4k形式的偶数
def quadruple(x):
    return x * 4

## 使用回调函数的中间函数，也就是回调函数的使用者
#中间函数
#接受一个生成偶数的函数作为参数
#返回一个奇数
def getOddNumber(k, getEvenNumber):
    return 1 + getEvenNumber(k)
    
#起始函数，这里是程序的主函数
def main():    
    k = 1
    #当需要生成一个2k+1形式的奇数时
    i = getOddNumber(k, double)
    print(i)
    #当需要一个4k+1形式的奇数时
    i = getOddNumber(k, quadruple)
    print(i)
    #当需要一个8k+1形式的奇数时
    i = getOddNumber(k, lambda x: x * 8)
    print(i)
    
if __name__ == &quot;__main__&quot;:
    main()
</code></pre>
<p>可以发现，其实我们只需要知道回调函数是<strong>传入什么参数，有什么功能即可</strong>，而不能自己去定义传入参数，<strong>所以我们去写回调函数的时候要按照中间函数传入的参数去写</strong>。</p>
<h2 id="2-keras中的回调函数">2 keras中的回调函数</h2>
<p>这里我们不讲那些keras中已经定义的回调函数，这里说一下如何创建自己的回调函数。
keras中定义了一个回调函数的抽象类，这个类包含多个回调函数（即一个类里面有很多方法，这些方法是不同的时期被中间函数调用的）。我们继承这个类，然后重新其中的回调函数即可。
下面看一下这个基类：
https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L275</p>
<pre><code class="language-python">class Callback(object):
			 &quot;&quot;&quot;Abstract base class used to build new callbacks.
    # Properties
        params: dict. Training parameters
            (eg. verbosity, batch size, number of epochs...).
        model: instance of `keras.models.Model`.
            Reference of the model being trained.
    The `logs` dictionary that callback methods
    take as argument will contain keys for quantities relevant to
    the current batch or epoch.
    Currently, the `.fit()` method of the `Sequential` model class
    will include the following quantities in the `logs` that
    it passes to its callbacks:
        on_epoch_end: logs include `acc` and `loss`, and
            optionally include `val_loss`
            (if validation is enabled in `fit`), and `val_acc`
            (if validation and accuracy monitoring are enabled).
        on_batch_begin: logs include `size`,
            the number of samples in the current batch.
        on_batch_end: logs include `loss`, and optionally `acc`
            (if accuracy monitoring is enabled).
    &quot;&quot;&quot;
		
     def __init__(self):
        self.validation_data = None
        self.model = None
		
		## 注意：set params和 set_model是已经定义好的，也就是说继承这个类以后回调函数本身就会有self.params 和self.model，不需要我们去关心有没有或者怎么得到这两个变量。
		# 既然是回调函数，那么params这个参数是中间函数传给它的，不需要我们去传。
    def set_params(self, params): 
        self.params = params

    def set_model(self, model):
        self.model = model
		
		## 什么时候会调用，直接可以看方法名。
		# Arguments
    #       logs: 具体可以看上面链接中给出的注释，每个都不一样。
	def on_batch_begin(self, batch, logs=None)
	def on_batch_end(self, batch, logs=None)
	def on_epoch_begin(self, epoch, logs=None)
	def on_epoch_end(self, epoch, logs=None)
	def on_train_batch_begin(self, batch, logs=None)
	def on_train_batch_end(self, batch, logs=None)
	def on_test_batch_begin(self, batch, logs=None)
	def on_test_batch_end(self, batch, logs=None)
	def on_predict_batch_begin(self, batch, logs=None)
	def on_predict_batch_end(self, batch, logs=None)
	def on_train_begin(self, logs=None)
	def on_train_end(self, logs=None)
	def on_test_begin(self, logs=None)
	def on_test_end(self, logs=None)
	def on_predict_begin(self, logs=None)
	def on_predict_end(self, logs=None)	
</code></pre>
<p>在回调函数中可以使用这两个参数。</p>
<ul>
<li>
<pre><code>    self.params = params： 字典。训练参数， (例如，verbosity, batch size, number of epochs...)。可以打印出来看看。
</code></pre>
</li>
<li>
<pre><code>    self.model = model：keras.models.Model 的实例。 指代被训练模型。
</code></pre>
</li>
</ul>
<p>通过类的属性 self.model，回调函数可以获得它所联系的模型。</p>
<h3 id="keras自定义回调函数的例子">keras自定义回调函数的例子</h3>
<p>回调函数使用以后，还可以通过类实例来访问实例变量。</p>
<pre><code class="language-python">class LossHistory(keras.callbacks.Callback):
    def __init__(self):
				super(LossHistory, self).__init__()
				self.losses = []
				
    def on_train_begin(self, logs={}):
        self.losses = []

    def on_batch_end(self, batch, logs={}):
        self.losses.append(logs.get('loss'))

model = Sequential()
model.add(Dense(10, input_dim=784, kernel_initializer='uniform'))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

history = LossHistory()
model.fit(x_train, y_train, batch_size=128, epochs=20, verbose=0, callbacks=[history])

print(history.losses)
</code></pre>
<h2 id="引用">引用</h2>
<ul>
<li>https://github.com/chensvm/Keras-Callback-F1/blob/master/roc_auc_score_Metrics</li>
<li>https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L275</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CV-Paper-超分辨率-Image super-resolution using a dilated convolutional neural network]]></title>
        <id>https://jzq6520.github.io/post/cv-paper-chao-fen-bian-lu-image-super-resolution-using-a-dilated-convolutional-neural-network</id>
        <link href="https://jzq6520.github.io/post/cv-paper-chao-fen-bian-lu-image-super-resolution-using-a-dilated-convolutional-neural-network">
        </link>
        <updated>2019-05-07T09:02:24.000Z</updated>
        <content type="html"><![CDATA[<h1 id="image-super-resolution-using-a-dilated-convolutional-neural-network">Image super-resolution using a dilated convolutional neural network</h1>
<p>这是一篇很有意思的文章，首先他的应用场景是超分辨率，然后他用到的网络结合了很多优秀的结构，通过这些优秀的结构解决了很多超分辨中的问题。</p>
<p>而且这个网络非常简单，并且很优雅，让人流连忘返。</p>
<p>文章提出的网络主要有以下几个部件组成：</p>
<ol>
<li><strong>空洞卷积</strong>（或叫扩张卷积，dilated convolutional);</li>
<li><strong>跨越连接</strong>（skip connect）；</li>
<li><strong>不下采样</strong>，保留分辨率。</li>
</ol>
<h2 id="1-网络">1 网络</h2>
<p><img src="https://jzq6520.github.io/post-images/1557220077383.png" alt=""></p>
<p>从上图可以看到以下几点：</p>
<ul>
<li>网络的<strong>输入输出大小是一样的</strong>，那么如何获得超分辨率的图像的，是这样的，首先将图像插值放大到2倍，然后输入到这个网络中，网络输出的是分辨率一样，但是细节更加清晰的图像。</li>
<li><strong>网络只有7层</strong>，是一个非常小的网络，因为在使用空洞卷积的到时候，网络并没有进行下采样，所以造成显存和计算量会占用很大，所以文章采用了较小的网络，实现了节省计算资源和显存的作用。</li>
<li>使用了<strong>skip连接</strong>，使用skip连接是将<strong>低维信息和高维相结合</strong>，低维信息往往代表一些<strong>图像的细节</strong>，而高维信息往往表示一些高维的<strong>语义特征</strong>，所以通过skip连接然网络的数据具有更多的细节，从而这个超分辨率网络才会更好。</li>
<li>使用了<strong>空洞卷积</strong>（dilated conv），空洞卷积具有<strong>保留信息</strong>而<strong>增加感受野</strong>的作用，所以空洞卷积在分割和检测中也常常使用。</li>
</ul>
<h2 id="2-放大超过两倍">2 放大超过两倍</h2>
<p>如果想将图像放大4倍、5倍或者跟大，那要怎么实现呢？ 文章利用联机的方式来进行放大，只需要将图像多次经过超分辨率网络就可以实现，如果放大倍数不是2的倍数，那么怎么办呢？ 这时候我们可以先放大，再缩小。例如想放大3倍，我们可以先放大4倍，然后再进行下采样即可。</p>
<p><img src="https://jzq6520.github.io/post-images/1557220626079.png" alt=""></p>
<h2 id="3-引用">3 引用</h2>
<ul>
<li>Image super-resolution using a dilated convolutional neural network</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CV-Paper-文字检测-Character Region Awareness for Text Detection]]></title>
        <id>https://jzq6520.github.io/post/cv-paper-wen-zi-jian-ce-character-region-awareness-for-text-detection</id>
        <link href="https://jzq6520.github.io/post/cv-paper-wen-zi-jian-ce-character-region-awareness-for-text-detection">
        </link>
        <updated>2019-05-06T11:46:34.000Z</updated>
        <content type="html"><![CDATA[<h1 id="character-region-awareness-for-text-detection-基于字符识别的文字检测">Character Region Awareness for Text Detection 基于字符识别的文字检测</h1>
<p>这篇文章是利用关键点检测的思想来进行文字检测。检测单个<strong>字符</strong>，并且识别出哪些字符是组成<strong>文字</strong>的，这样就可以检测出一组组文字。</p>
<p>以前的一些方法都是检测word-level的bounding box，但是这样会遇到一些难点，例如文字是弯曲的，不规则的，或则是特别长的。如果是基于character-level的话就没用这些难点了，因为是检测单个字符，所以没有文字形状的规定，并且，只需要小的感受野即可以了， 但是以前的检测包围框的方法就需要很大的感受野才行。</p>
<p><strong>那么，基于单个字符区域的文字检测存在两个难点</strong>：</p>
<ol>
<li>如何确定哪些字符是连接在一起组成文字的，而哪些字符是分离的；</li>
<li>数据标注问题，因为当前的数据集都是文字级别（word-level）的标注。</li>
</ol>
<p>下面分别来说明解决这两个难点的方法。</p>
<h2 id="1-确定哪些字符是连接的">1 确定哪些字符是连接的</h2>
<p><strong>字符检测</strong>：本文使用的网络使用了目前关键点检测中常用的网络结构，即采用预测热图的方式来进行检测关键点，那么在这里我们就可以把每个<strong>字符</strong>当做一个关键点，所以每个<strong>字符</strong>其实对应着一个<strong>热点</strong>，只要预测每个文字所对应的热点那么就可检测出每个字符。</p>
<p><strong>字符连接的识别</strong>：那么，现在字符的检测方法有了，我们要怎么知道哪些字符是组成一个文字的。这里我觉得作者特别聪明，作者也使用热图的方式来表示文字的连接，如果两个字符是相连接的，那么这两个字符之间就有一个<strong>热点</strong>。很高明的做法，利用热点图来确定两个字符是不是一组的。</p>
<p>热点就代表着一个响应，如果图片中的某个地方有热点响应，那么表示这个地方存在我们需要的信息，热点的值的大小就代表着置信度，如果置信度越高，那么越确定。</p>
<h3 id="11-ground-truth-构造">1.1 ground truth 构造</h3>
<p>如何构造我们的监督信息，可以看下面这幅图。
<img src="https://jzq6520.github.io/post-images/1557144607556.png" alt=""></p>
<p>从上图可以看出，我们的监督信息（或者说网络的预测）有两个，一个是Region Score GT（区域分数），这个是预测字符位置的热图，另外一个是Affinity Score GT（关联分数），这个是预测两个字符是否<strong>关联</strong>的热图。</p>
<p>region score其实就是单个字符的包围框的一个二维高斯图，他是通过对<strong>二维正态分布的高斯图</strong>进行仿射变换得到的。
Affinity Score 通过画对角线来连接每个字符框的对角，我们可以生成两个三角形——我们将其称为上字符三角形和下字符三角形。然后，对于每个相邻的字符框对，通过将上三角形和下三角形的中心设置为框的角，生成一个关联框。然后将<strong>二维正态分布的高斯图</strong>进行仿射变换到关联框来获得对应的热图。</p>
<h2 id="2-数据标注问题-获得字符级别character-level的标注">2 数据标注问题-获得字符级别（Character-level）的标注</h2>
<p>如果想通过人工进行对字符进行标注，那么可想而知是非常耗时的。所以本文使用<strong>人工生成数据和弱监督</strong>结合的方式来解决这个问题。</p>
<h3 id="21-人工生成数据">2.1 人工生成数据</h3>
<p><img src="https://jzq6520.github.io/post-images/1557145267677.png" alt="">
人工生成就是将文字黏贴到一下图片上，这时候因为是自己的文字，所以我们可以有字符级别的包围框，所以我们就有了字符级别的标注。</p>
<h3 id="22-弱监督">2.2 弱监督</h3>
<p><img src="https://jzq6520.github.io/post-images/1557145261386.png" alt=""></p>
<p>上图就是一个弱监督的网络框架，作者将人工生成的数据和我们word-level标注数据一起进行训练。红色箭头预测的是region score，然后经过字符检测的热图来得到每个字符的框，这样进一步又可以得到affinity score的热图。这样就间接获得了文字的affinity score的热图。然后将预测得到的两个score热图作为ground truth进一步监督网络的训练。</p>
<p>当使用弱监督训练模型时，我们被迫训练不完整的伪GT。 如果使用不准确的区域分数训练模型，则输出可能在字符区域内模糊。 为了防止这种情况，我们测量模型生成的每个伪GT的质量。 幸运的是，文本注释中有一个非常强大的提示，即单词长度。 在大多数数据集中，提供了单词的转录，并且单词的长度可用于评估伪GT的置信度。</p>
<p>所以我们在训练的时候要根据<strong>伪GT</strong>的置信度来计算loss，如果生成的GT和真实情况很接近，那么这个loss就是有用的，如果生成的GT都很假，我们肯定是不接受这个loss。所以loss的计算方式如下：
<img src="https://jzq6520.github.io/post-images/1557145511065.png" alt=""></p>
<p>那么如何计算这个置信度呢，我们可以通过计算伪GT的字符长度和真实的GT的字符长度比较来得到：
<img src="https://jzq6520.github.io/post-images/1557145731860.png" alt=""></p>
<p>L(w)表示单词的长度，右上角加c的表示预测的得到的长度，取min得到的是不大于L(w)的值，这样Sconf的值就不会是负数，并且Sconf的值是0~1之间的。</p>
<p>并且预测的热图在这个单词的包围框外面则权重为1，其实简单的理解就是只在word的包围框内的时候它的loss需要加权，因为word（所有的单词区域）包围框外面是没有文字的，所以只要预测出来有字符那么都是假阳。
<img src="https://jzq6520.github.io/post-images/1557146064702.png" alt=""></p>
<h3 id="23-弱监督gt的生成过程">2.3 弱监督GT的生成过程</h3>
<p><img src="https://jzq6520.github.io/post-images/1557146113840.png" alt="">
如图所示，就是先根据word-level标注的数据，将单词切出来，然后再进行预测，得到热图以后再进行处理。</p>
<h2 id="3-热图预测网络">3 热图预测网络</h2>
<p>最后热图预测的网络是一个类U-net的网络。
<img src="https://jzq6520.github.io/post-images/1557146202867.png" alt=""></p>
<h2 id="4-网络收敛过程">4 网络收敛过程</h2>
<p><img src="https://jzq6520.github.io/post-images/1557146285216.png" alt=""></p>
<h2 id="5-网络预测性能">5 网络预测性能</h2>
<p><img src="https://jzq6520.github.io/post-images/1557146323704.png" alt=""></p>
<h2 id="6-引用">6 引用</h2>
<p>论文：Character Region Awareness for Text Detection</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CV-Paper-文字检测-Shape Robust Text Detection PSENet]]></title>
        <id>https://jzq6520.github.io/post/cv-paper-wen-zi-jian-ce-shape-robust-text-detection-psenet</id>
        <link href="https://jzq6520.github.io/post/cv-paper-wen-zi-jian-ce-shape-robust-text-detection-psenet">
        </link>
        <updated>2019-04-30T06:39:38.000Z</updated>
        <content type="html"><![CDATA[<h1 id="shape-robust-text-detection-with-progressive-scale-expansion-network">Shape Robust Text Detection with Progressive Scale Expansion Network</h1>
<p>这篇文章是利用分割方法来做文字检测，主要克服了弯曲的文字区域检测问题。所以这篇文章叫做形状鲁棒性的文字检测。</p>
<p>主要有以下几个重点思想：</p>
<ol>
<li>利用分割方法来做检测，提高了对非矩形文字区域检测的鲁棒性；</li>
<li>利用Progressive Scale Expansion方法实现了instance segment（实例分割）；</li>
<li>多尺度分割。</li>
</ol>
<p>当然这篇文章的方法对于矩形区域的文字检测也是相当准确的。</p>
<h2 id="1-网络">1 网络</h2>
<p>首先来看一下这篇文章使用的网络结构，如下图所示。
<img src="https://jzq6520.github.io/post-images/1556608333773.png" alt="network"></p>
<p>作者是将这个网络分成两个部分来讲述，左边是一个FPN结构，右边是一个特征融合部分和progressive scale expansion部分。</p>
<p>其实我个人是把这个网络看做分割网络和后处理两个部分。</p>
<p>首先从网络输入到mask预测输出看做分割部分，后面将多个分割结果整合成一个最终的结果看做是progressive scale expansion后处理部分。</p>
<h3 id="11-分割网络">1.1 分割网络</h3>
<p>分割网络由FPN, 特征融合，加上一个预测组成。</p>
<p>首先分割网络采用了几个技术：</p>
<ol>
<li>FPN： FPN是一个解决多尺度的常用的解决方案，上采样的不同层的feature map大小不一样，从大到小，这样在小的featuremap上检测相对大的目标，在大的featuremap上可以检测相对小的目标（因为分辨率更高），实现了一个多尺度检测；</li>
<li>concat：concat在图像处理中也经常遇到，经常用来融合不同尺度或不同层级特征的信息，在这里就是将各个不同尺度的特征图（feature map）的特征进行融合，实现一个多尺度的识别。</li>
<li>concat后面的卷积：concat只是简单的将特征堆叠起来，后面一般会接一个conv层来融合特征。</li>
<li>concat后的卷积还用了一次upsample，即上采样，这是因为FPN最后一层的数据是原图的一半，所以这里特征融合一个又进行了一次上采样来让预测结果和原图一样大小。</li>
<li>sigmoid来预测n个mask。</li>
</ol>
<h3 id="12-后处理">1.2 后处理</h3>
<p>后处理采用的是一个简单的像素点划分，有点类似区域生长，只是说在一个范围内进行区域生长。</p>
<p>mask最小的预测结果实现了instance分割，即每个文字块是相互分离的。最大的mask就是最终的分割结果（但是没有进行instance分割），但有时候文字块区域是相互黏连的，所以需要通过最小的mask的信息来讲这些黏连的区域分离。</p>
<p>具体过程就如下所示：
<img src="https://jzq6520.github.io/post-images/1556609357492.png" alt="scale expansen"></p>
<p>扩展基于广度优先搜索算法，该算法从多个内核的像素开始，迭代地合并相邻的文本像素。对于冲突的像素，只能被一个kernel合并，通过先到先得的规则合并。由于是这种根据下一个mask的边界来扩展区域的，所以不会影响最后的结果。</p>
<h2 id="2-构建数据集">2 构建数据集</h2>
<p><img src="https://jzq6520.github.io/post-images/1556610390720.png" alt=""></p>
<p>需要创建多个不同目标大小（经过不同尺度的缩小）的mask。文章中是使用图形学的方法来进行创建的。但是我决定也可以使用形态学腐蚀的方法创建。</p>
<p>文章使用Vatti clipping algorithm方法来进行mask的腐蚀。
腐蚀的边界距离是通过这个公式计算得到的：
<img src="https://jzq6520.github.io/post-images/1556610096797.png" alt=""></p>
<p>并且缩小的倍数是计算得到的，其实就是一个插值得到中间的倍数，例如从0.4-1倍，总共5个mask，那么就不是完整的从0.4，0.5，0.6，...这样下去，所以还是要计算一下的。公式如下：
<img src="https://jzq6520.github.io/post-images/1556610255688.png" alt=""></p>
<p>m表示最低是多少倍，n表示有几个mask，r就是倍数，d是边界到腐蚀以后边界的距离，p表示mask区域。</p>
<p>代码：</p>
<pre><code class="language-python">import pyclipper
import Polygon as plg
def get_bboxes(img, gt_path):
    h, w = img.shape[0:2]
    lines = util.io.read_lines(gt_path)
    bboxes = []
    tags = []
    for line in lines:
        line = util.str.remove_all(line, '\xef\xbb\xbf')
        gt = util.str.split(line, ',')

        x1 = np.int(gt[0])
        y1 = np.int(gt[1])

        bbox = [np.int(gt[i]) for i in range(4, 32)]
        bbox = np.asarray(bbox) + ([x1 * 1.0, y1 * 1.0] * 14)
        bbox = np.asarray(bbox) / ([w * 1.0, h * 1.0] * 14)
        
        bboxes.append(bbox)
        tags.append(True)
    return np.array(bboxes), tags
		
def dist(a, b):
    return np.sqrt(np.sum((a - b) ** 2))

def perimeter(bbox):
    peri = 0.0
    for i in range(bbox.shape[0]):
        peri += dist(bbox[i], bbox[(i + 1) % bbox.shape[0]])
    return peri

def shrink(bboxes, rate, max_shr=20):
    rate = rate * rate
    shrinked_bboxes = []
    for bbox in bboxes:
        area = plg.Polygon(bbox).area()
        peri = perimeter(bbox)

        pco = pyclipper.PyclipperOffset()
        pco.AddPath(bbox, pyclipper.JT_ROUND, pyclipper.ET_CLOSEDPOLYGON)
        offset = min((int)(area * (1 - rate) / (peri + 0.001) + 0.5), max_shr)
        
        shrinked_bbox = pco.Execute(-offset)
        if len(shrinked_bbox) == 0:
            shrinked_bboxes.append(bbox)
            continue
        
        shrinked_bbox = np.array(shrinked_bbox[0])
        if shrinked_bbox.shape[0] &lt;= 2:
            shrinked_bboxes.append(bbox)
            continue
        
        shrinked_bboxes.append(shrinked_bbox)
    
    return np.array(shrinked_bboxes)
</code></pre>
<h2 id="3-损失函数-loss">3 损失函数 LOSS</h2>
<p>损失由完整的mask的loss加上腐蚀以后mask的loss，其中两项是加权相加：
<img src="https://jzq6520.github.io/post-images/1556610560713.png" alt="">
c表示完整的（complete），s表示（腐蚀后的，shrunk），Ls是所以腐蚀后的mask loss相加得到的。
使用1-dice coefﬁcient作为loss，来避免样本不平衡（前景和背景）的影响。dice coefﬁcient计算如下：
<img src="https://jzq6520.github.io/post-images/1556610778071.png" alt=""></p>
<p><img src="https://jzq6520.github.io/post-images/1556610842164.png" alt="">
并且腐蚀后的mask的loss是在预测区域（注意不是标注区域内）内计算的，这个和之前我其他任务中在G里面计算loss不一样，这个是在预测的区域内计算loss，这样的一个好处可能是假阳会少，因为如果在G里面计算，那么G外面预测的假阳就没用计算在loss里面。</p>
<p>最后还使用了在线难例挖掘。</p>
<h2 id="4-augment">4 augment</h2>
<p>数据增强使用了，水平翻转，随机旋转，随机缩放，随机剪裁640x640大小。
代码：</p>
<pre><code class="language-python">import pyclipper
import Polygon as plg
def random_horizontal_flip(imgs):
    if random.random() &lt; 0.5:
        for i in range(len(imgs)):
            imgs[i] = np.flip(imgs[i], axis=1).copy()
    return imgs

def random_rotate(imgs):
    max_angle = 10
    angle = random.random() * 2 * max_angle - max_angle
    for i in range(len(imgs)):
        img = imgs[i]
        w, h = img.shape[:2]
        rotation_matrix = cv2.getRotationMatrix2D((h / 2, w / 2), angle, 1)
        img_rotation = cv2.warpAffine(img, rotation_matrix, (h, w))
        imgs[i] = img_rotation
    return imgs

def scale(img, long_size=2240):
    h, w = img.shape[0:2]
    scale = long_size * 1.0 / max(h, w)
    img = cv2.resize(img, dsize=None, fx=scale, fy=scale)
    return img

def random_scale(img, min_size):
    h, w = img.shape[0:2]
    if max(h, w) &gt; 1280:
        scale = 1280.0 / max(h, w)
        img = cv2.resize(img, dsize=None, fx=scale, fy=scale)

    h, w = img.shape[0:2]
    random_scale = np.array([0.5, 1.0, 2.0, 3.0])
    scale = np.random.choice(random_scale)
    if min(h, w) * scale &lt;= min_size:
        scale = (min_size + 10) * 1.0 / min(h, w)
    img = cv2.resize(img, dsize=None, fx=scale, fy=scale)
    return img

def random_crop(imgs, img_size):
    h, w = imgs[0].shape[0:2]
    th, tw = img_size
    if w == tw and h == th:
        return imgs
    
    if random.random() &gt; 3.0 / 8.0 and np.max(imgs[1]) &gt; 0:
        tl = np.min(np.where(imgs[1] &gt; 0), axis = 1) - img_size
        tl[tl &lt; 0] = 0
        br = np.max(np.where(imgs[1] &gt; 0), axis = 1) - img_size
        br[br &lt; 0] = 0
        br[0] = min(br[0], h - th)
        br[1] = min(br[1], w - tw)
        
        i = random.randint(tl[0], br[0])
        j = random.randint(tl[1], br[1])
    else:
        i = random.randint(0, h - th)
        j = random.randint(0, w - tw)
    
    # return i, j, th, tw
    for idx in range(len(imgs)):
        if len(imgs[idx].shape) == 3:
            imgs[idx] = imgs[idx][i:i + th, j:j + tw, :]
        else:
            imgs[idx] = imgs[idx][i:i + th, j:j + tw]
    return imgs
</code></pre>
<h2 id="5-最后">5 最后</h2>
<p>细节可看论文，这里只介绍了文章的主要思想和内容。</p>
<h2 id="6-引用">6 引用</h2>
<ul>
<li>Shape Robust Text Detection with Progressive Scale Expansion Network</li>
<li>https://github.com/whai362/PSENet</li>
<li>https://github.com/whai362/PSENet/blob/master/dataset/ctw1500_loader.py#L40</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[LeetCode-sql]]></title>
        <id>https://jzq6520.github.io/post/leetcode-sql</id>
        <link href="https://jzq6520.github.io/post/leetcode-sql">
        </link>
        <updated>2019-04-29T06:34:50.000Z</updated>
        <content type="html"><![CDATA[<h1 id="leetcode-sql-刷题">LeetCode sql 刷题</h1>
<h2 id="自身和自身比较">自身和自身比较</h2>
<pre><code>mysql&gt; select * from salary;
+------+------+
| id   | sala |
+------+------+
|    1 |  200 |
|    2 |  300 |
|    3 |  400 |
|    4 |  500 |
+------+------+
4 rows in set (0.00 sec)

</code></pre>
<pre><code>mysql&gt; select a.id as a_id,a.sala as a_sala,b.id as b_id,b.sala as b_sala from salary a,salary b where a.sala&gt;b.sala
    -&gt; ;
+------+--------+------+--------+
| a_id | a_sala | b_id | b_sala |
+------+--------+------+--------+
|    2 |    300 |    1 |    200 |
|    3 |    400 |    1 |    200 |
|    4 |    500 |    1 |    200 |
|    3 |    400 |    2 |    300 |
|    4 |    500 |    2 |    300 |
|    4 |    500 |    3 |    400 |
+------+--------+------+--------+
6 rows in set (0.01 sec)
</code></pre>
<p>下面这个一直想不通，是否是b 表满足子查询总的b的条件</p>
<pre><code>mysql&gt; select b.* from salary b where 2 &gt; (select count(distinct a.sala) from salary a where a.sala&gt;b.sala)
    -&gt; ;
+------+------+
| id   | sala |
+------+------+
|    3 |  400 |
|    4 |  500 |
+------+------+
2 rows in set (0.00 sec)
</code></pre>
<h2 id="184-department-highest-salar">184. Department Highest Salar</h2>
<p>问题：</p>
<pre><code>The Employee table holds all employees. Every employee has an Id, a salary, and there is also a column for the department Id.

+----+-------+--------+--------------+
| Id | Name  | Salary | DepartmentId |
+----+-------+--------+--------------+
| 1  | Joe   | 70000  | 1            |
| 2  | Henry | 80000  | 2            |
| 3  | Sam   | 60000  | 2            |
| 4  | Max   | 90000  | 1            |
+----+-------+--------+--------------+
The Department table holds all departments of the company.

+----+----------+
| Id | Name     |
+----+----------+
| 1  | IT       |
| 2  | Sales    |
+----+----------+
Write a SQL query to find employees who have the highest salary in each of the departments. For the above tables, Max has the highest salary in the IT department and Henry has the highest salary in the Sales department.

+------------+----------+--------+
| Department | Employee | Salary |
+------------+----------+--------+
| IT         | Max      | 90000  |
| Sales      | Henry    | 80000  |
+------------+----------+--------+
</code></pre>
<p>解：可以使用多个条件进行一起过滤，但是e.DepartmentId, e.Salary这个顺序，要和in里面的字段的顺序要一样。</p>
<pre><code># Write your MySQL query statement below

select 
    d.Name as 'Department',
    e.Name as 'Employee',
    e.Salary as 'Salary'
from
Employee e
join 
Department d on e.DepartmentId = d.Id
where 
(e.DepartmentId, e.Salary) in
(
    select a.DepartmentId,
            max(a.Salary) 
    from Employee a
    group by a.DepartmentId
)
;

</code></pre>
<h2 id="177-nth-highest-salary">177. Nth Highest Salary</h2>
<p>LIMIT 来定位数据。</p>
<pre><code>Write a SQL query to get the nth highest salary from the Employee table.

+----+--------+
| Id | Salary |
+----+--------+
| 1  | 100    |
| 2  | 200    |
| 3  | 300    |
+----+--------+
For example, given the above Employee table, the nth highest salary where n = 2 is 200. If there is no nth highest salary, then the query should return null.

+------------------------+
| getNthHighestSalary(2) |
+------------------------+
| 200                    |
+------------------------+
</code></pre>
<p>解：mysql还是要再看看。</p>
<pre><code>CREATE FUNCTION getNthHighestSalary(N INT) RETURNS INT
BEGIN
    DECLARE M INT;
    set M = N-1;
  RETURN (
      # Write your MySQL query statement below.
      #初始记录行的偏移量是 0,第n个，就是包括第n个，那么索引就是N-1
     SELECT DISTINCT Salary FROM Employee ORDER BY Salary DESC LIMIT M, 1
     
  );
END
</code></pre>
<h2 id="601-human-traffic-of-stadium">601. Human Traffic of Stadium</h2>
<p>难度很高的一道题</p>
<pre><code>X city built a new stadium, each day many people visit it and the stats are saved as these columns: id, date, people

Please write a query to display the records which have 3 or more consecutive rows and the amount of people more than 100(inclusive).

For example, the table stadium:
+------+------------+-----------+
| id   | date       | people    |
+------+------------+-----------+
| 1    | 2017-01-01 | 10        |
| 2    | 2017-01-02 | 109       |
| 3    | 2017-01-03 | 150       |
| 4    | 2017-01-04 | 99        |
| 5    | 2017-01-05 | 145       |
| 6    | 2017-01-06 | 1455      |
| 7    | 2017-01-07 | 199       |
| 8    | 2017-01-08 | 188       |
+------+------------+-----------+
For the sample data above, the output is:

+------+------------+-----------+
| id   | date       | people    |
+------+------------+-----------+
| 5    | 2017-01-05 | 145       |
| 6    | 2017-01-06 | 1455      |
| 7    | 2017-01-07 | 199       |
| 8    | 2017-01-08 | 188       |
+------+------------+-----------+
</code></pre>
<p>解：几个点，首先考察如何判断三个连续的值，建立三个原表的引用，where三个引用，那么形成的是一个笛卡尔积。</p>
<pre><code>select distinct t1.*
from stadium t1, stadium t2, stadium t3
where t1.people &gt;= 100 and t2.people &gt;= 100 and t3.people &gt;= 100
;
</code></pre>
<p>这个结果出来的是满足大于100的值。
Considering t1, t2 and t3 are identical, we can take one of them to consider what conditions we should add to filter the data and get the final result. Taking t1 for example, it could exist in the beginning of the consecutive 3 days, or the middle, or the last.</p>
<ul>
<li>t1 in the beginning: (t1.id - t2.id = 1 and t1.id - t3.id = 2 and t2.id - t3.id =1) -- t1, t2, t3</li>
<li>t1 in the middle: (t2.id - t1.id = 1 and t2.id - t3.id = 2 and t1.id - t3.id =1) -- t2, t1, t3</li>
<li>t1 in the end: (t3.id - t2.id = 1 and t2.id - t1.id =1 and t3.id - t1.id = 2) -- t3, t2, t1</li>
</ul>
<pre><code>select t1.*
from stadium t1, stadium t2, stadium t3
where t1.people &gt;= 100 and t2.people &gt;= 100 and t3.people &gt;= 100
and
(
      (t1.id - t2.id = 1 and t1.id - t3.id = 2 and t2.id - t3.id =1)  -- t1, t2, t3
    or
    (t2.id - t1.id = 1 and t2.id - t3.id = 2 and t1.id - t3.id =1) -- t2, t1, t3
    or
    (t3.id - t2.id = 1 and t2.id - t1.id =1 and t3.id - t1.id = 2) -- t3, t2, t1
)
;
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SQL学习笔记-sql内建函数]]></title>
        <id>https://jzq6520.github.io/post/sql-xue-xi-bi-ji-sql-nei-jian-han-shu</id>
        <link href="https://jzq6520.github.io/post/sql-xue-xi-bi-ji-sql-nei-jian-han-shu">
        </link>
        <updated>2019-04-29T06:30:51.000Z</updated>
        <content type="html"><![CDATA[<p>这里只记录了一点重要的语句，其他的可以用到的时候百度。</p>
<h1 id="sql-内建函数">sql 内建函数</h1>
<p>SQL 拥有很多可用于计数和计算的<a href="http://www.w3school.com.cn/sql/sql_functions.asp">内建函数</a>。
函数的语法
内建 SQL 函数的语法是：</p>
<pre><code class="language-sql">SELECT function(列) FROM 表
</code></pre>
<h2 id="函数的类型">函数的类型</h2>
<p>在 SQL 中，基本的函数类型和种类有若干种。函数的基本类型是：</p>
<ul>
<li>Aggregate 合计函数：Aggregate 函数的操作面向一系列的值，并返回一个单一的值。</li>
<li>Scalar 纯量函数：Scalar 函数的操作面向某个单一的值，并返回基于输入值的一个单一的值。</li>
</ul>
<h2 id="group-by-分组语句">GROUP BY 分组语句</h2>
<p>GROUP BY 语句用于结合合计函数，根据一个或多个列对结果集进行分组。
例如可以对人进行分组，再使用sum函数，对每个人计算他的工资。</p>
<pre><code class="language-sql">SELECT column_name, aggregate_function(column_name)
FROM table_name
WHERE column_name operator value
GROUP BY column_name
</code></pre>
<h2 id="having-子句">HAVING 子句</h2>
<p>在 SQL 中增加 HAVING 子句原因是，WHERE 关键字无法与合计函数一起使用。就相当于普通语句中的where。</p>
<pre><code class="language-sql">SELECT column_name, aggregate_function(column_name)
FROM table_name
WHERE column_name operator value
GROUP BY column_name
HAVING aggregate_function(column_name) operator value
</code></pre>
<p>例如可以这么写：</p>
<pre><code class="language-sql">SELECT Customer,SUM(OrderPrice) FROM Orders
GROUP BY Customer
HAVING SUM(OrderPrice)&lt;2000
</code></pre>
<h2 id="format-函数">FORMAT() 函数</h2>
<p>FORMAT 函数用于对字段的显示进行格式化。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MySQL学习笔记-pymysql]]></title>
        <id>https://jzq6520.github.io/post/mysql-xue-xi-bi-ji-pymysql</id>
        <link href="https://jzq6520.github.io/post/mysql-xue-xi-bi-ji-pymysql">
        </link>
        <updated>2019-04-29T06:28:24.000Z</updated>
        <content type="html"><![CDATA[<h1 id="pymysql">pymysql</h1>
<p>pymysql 是在py3和py2上都可以使用的连接 MySQL 服务器的一个库。</p>
<h2 id="事务">事务</h2>
<p>事务机制可以确保数据一致性。
事务应该具有4个属性：原子性、一致性、隔离性、持久性。这四个属性通常称为ACID特性。</p>
<ul>
<li>原子性（atomicity）。一个事务是一个不可分割的工作单位，事务中包括的诸操作要么都做，要么都不做。</li>
<li>一致性（consistency）。事务必须是使数据库从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的。</li>
<li>隔离性（isolation）。一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。</li>
<li>持久性（durability）。持续性也称永久性（permanence），指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。
Python DB API 2.0 的事务提供了两个方法 commit 或 rollback。</li>
</ul>
<h2 id="安装">安装</h2>
<p>首先查看了conda库中是否有这个包<code>conda search pymysql</code>，发现是有的并且有py2.7版本，直接安装<code>conda install pymysql</code></p>
<h2 id="cursor游标">cursor游标</h2>
<p>游标就像一辆货车，把指令带过去执行(execute)，然后运回来值(fetch*)。</p>
<h2 id="fetch">fetch</h2>
<ul>
<li>fetchone(): 该方法获取下一个查询结果集。结果集是一个对象</li>
<li>fetchall(): 接收全部的返回结果行.</li>
<li>rowcount: 这是一个只读属性，并返回执行execute()方法后影响的行数。</li>
</ul>
<h2 id="使用">使用</h2>
<pre><code class="language-python">## 建立数据库连接
conn = pymysql.Connect(host='127.0.0.1',
							user='root',
							passwd='123456',
							db='python_mysql',
							charset='utf8')
# 使用 cursor() 方法创建一个游标对象 cursor
# 每一个游标对象传送一条sql
cursor = conn.cursor()
# 使用 execute()  方法执行 SQL 查询 
cursor.execute(&quot;SELECT VERSION()&quot;)
# 使用 fetchone() 方法获取单条数据.两个单词tetch one
# fetchall() 所有
conn.commit()
data = cursor.fetchone()
print (&quot;Database version : %s &quot; % data)
# 关闭数据库连接
db.close()
</code></pre>
<h2 id="代码">代码</h2>
<p>转账：</p>
<pre><code class="language-python"># -*- coding: UTF-8 -*-
import sys
import pymysql

class TransferMoney(object):
	def __init__(self, conn):
		self.conn = conn

	def check_acct_available(self, acctid):
		cursor = self.conn.cursor()
		try:
			sql = &quot;select * from account where acctid=%s&quot; % acctid
			cursor.execute(sql)
			print &quot;check_acct_available: &quot; + sql
			rs = cursor.fetchall()
			if len(rs) !=1:
				raise Exception(&quot;账号%s不存在&quot; % acctid)
		finally:
		#关闭cursor
			cursor.close()
	
	def has_enough_money(self, acctid, money):
		cursor = self.conn.cursor()
		try:
			sql = &quot;select money from account where acctid=%s and money &gt;= %s &quot; % (acctid, money)
			cursor.execute(sql)
			print &quot;has_enough_money: &quot; + sql
			rs = cursor.fetchall()
			if len(rs) != 1:
				raise Exception(&quot;账号%s金额不足,剩余金额为%s&quot;%(acctid, money))
		finally:
			cursor.close()

	def reduce_money(self, acctid, money):
		cursor = self.conn.cursor()
		try:
			sql = &quot;update account set money = money - %s where acctid=%s&quot;%(money, acctid)
			cursor.execute(sql)
			print &quot;reduce_money: &quot; + sql

			if cursor.rowcount !=1 :
				raise Exception(&quot;账号%s减款失败&quot;%(acctid))
		finally:
			cursor.close()

	def add_money(self, acctid, money):
		cursor = self.conn.cursor()
		try:
			sql = &quot;update account set money = money + %s where acctid=%s&quot;%(money, acctid)
			cursor.execute(sql)
			print &quot;add_money: &quot; + sql

			if cursor.rowcount !=1 : #判断被影响的行数：cursor.rowcount
				raise Exception(&quot;账号%s加款失败&quot;%(acctid))
		finally:
			cursor.close()


	def transfer(self, source_acctid, target_acctid, money):
		try:
			self.check_acct_available(source_acctid)
			self.check_acct_available(target_acctid)
			self.has_enough_money(source_acctid, money)
			self.reduce_money(source_acctid, money)
			self.add_money(target_acctid, money)
			# 向数据库提交，不开启自动提交
			self.conn.commit()
		except Exception as e:
		# 发生错误时回滚
			self.conn.rollback()
			raise e



if __name__ == &quot;__main__&quot;:
	source_acctid = sys.argv[1]
	target_acctid = sys.argv[2]
	money = sys.argv[3]

	conn = pymysql.Connect(host='127.0.0.1',
							user='root',
							passwd='123456',
							db='python_mysql',
							charset='utf8'
							)
	tr_money = TransferMoney(conn)

	try:
		tr_money.transfer(source_acctid, target_acctid, money)
	except Exception as e:
		print &quot;出现问题：&quot; + str(e)
	finally:
	# 关闭连接
		conn.close()

</code></pre>
<h2 id="引用">引用</h2>
<p><a href="http://www.runoob.com/python3/python3-mysql.html">1. http://www.runoob.com/python3/python3-mysql.html</a>
<a href="http://pymysql.readthedocs.io/en/latest/index.html">2. PyMySQL’s documentation</a>
<a href="https://github.com/PyMySQL/PyMySQL">3. https://github.com/PyMySQL/PyMySQL</a>
<a href="https://www.python.org/dev/peps/pep-0249/">4. https://www.python.org/dev/peps/pep-0249/</a></p>
]]></content>
    </entry>
</feed>