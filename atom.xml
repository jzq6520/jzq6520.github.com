<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://jzq6520.github.io</id>
    <title>chuck</title>
    <updated>2020-06-04T11:37:08.794Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://jzq6520.github.io"/>
    <link rel="self" href="https://jzq6520.github.io/atom.xml"/>
    <subtitle>天地不仁以万物为刍狗</subtitle>
    <logo>https://jzq6520.github.io/images/avatar.png</logo>
    <icon>https://jzq6520.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, chuck</rights>
    <entry>
        <title type="html"><![CDATA[目标检测--（anchor-free）FCOS: Fully Convolutional One-Stage Object Detection]]></title>
        <id>https://jzq6520.github.io/post/mu-biao-jian-ce-anchor-freefcos-fully-convolutional-one-stage-object-detection</id>
        <link href="https://jzq6520.github.io/post/mu-biao-jian-ce-anchor-freefcos-fully-convolutional-one-stage-object-detection">
        </link>
        <updated>2020-04-28T16:08:06.000Z</updated>
        <content type="html"><![CDATA[<h1 id="fcos-fully-convolutional-one-stage-object-detection">FCOS: Fully Convolutional One-Stage Object Detection</h1>
<p>取fullyz convolutional这样的名字是说明这个真的全是卷积，没有像其他一样还要计算anchor和目标box的iou等。</p>
<p>center-based的anchor-free的目标检测方法，中文也就是基于中心的不需要anchor的目标检测方法。<br>
预测的时候就像是做语义分割一样，每个像素预测，并且不需要定义anchor，就也不需要在过程中计算iou这些东西了，减少了很多的计算量，计算速度更快了，也更加简单了，后处理只需要非极大值抑制（NMS）。</p>
<h2 id="基于anchor的目标检测的缺点">基于anchor的目标检测的缺点</h2>
<p>基于anchor的目标检测有很多缺点：</p>
<ol>
<li>检测的精度和预先定义的anchor的大小、长宽比、还有数量有关。这些参数对于不一样大小的目标的检测任务时常常需要改动。</li>
<li>第二个其实也是anchor的问题，一旦anchor的大小、长宽比、数量缺点了以后，就固定了，所以碰上目标尺度变化较大的任务时，性能常常会下降。</li>
<li>anchor的样本不平衡问题，因为需要对目标有较高的召回率，所以都要设置非常密集的，非常多的anchor，不这样设置的话可能会有目标分配不到anchor。所以负样本的anchor会非常多，这给训练带来了困难。</li>
<li>计算量大，anchor越多计算量越大，例如给anchor打标签的时候就需要计算大量的IOU。</li>
</ol>
<p>基于anchor的目标检测，最开始是来自于传统的滑窗检测，当然anchor boxes可以被看做预先定义好的滑窗。<em>In anchor-based detectors, the anchor boxes can be viewed as pre-deﬁned sliding windows or proposals, which are classiﬁed as pos- itive or negative patches, with an extra offsets regression to reﬁne the prediction of bounding box locations。Therefore, the anchor boxes in these detectors may be viewed as training samples.</em></p>
<p>所以说anchor boxes可以看做训练样本。</p>
<h2 id="一些anchor-free框架的缺点">一些anchor-free框架的缺点</h2>
<p>例如YOLO-v1，yolo-v1的缺点就是召回率低，因为一个格子只预测理他最近的一个物体，格子又少，所以他的召回率其实非常低。</p>
<p>然后比如cornerNet，它检测box的一对角并将它们分组以形成最终检测到的box。 CornerNet需要更复杂的后处理，才能将属于同一实例的corner进行分组。 为了分组的目的，学习了额外的距离度量。</p>
<h2 id="fcos的关键概念">FCOS的关键概念</h2>
<ul>
<li>包围框内的点都是正样本，这样正负样本不平衡的问题就得到了缓和。</li>
<li>特征图上的每个点对应原图上的一个点，所以这就是物体的“中心”了，所以不需要再去回归中心的坐标；</li>
<li><strong>这里的中心可以理解为物体包围框（box）内的点</strong>。但是离目标包围框中心越远的点的权重(置信度)肯定是越低的,他<strong>回归出的边界距离的质量</strong>肯定也是较低的.</li>
<li>中心并不是box的中心，而是特征图上对应原图上的一个点，可以的特征图就是用来回归的那个特征图；</li>
<li>需要回归中“中心”到四个边的距离，因为这里的中心并不是box的真正的中心，所以这个中心到四个边的距离可以是不一样的，如果是真正的中心那么中心到左右是距离一样的（也就是宽的一半）；</li>
<li>落在目标box内的点就是正样本；</li>
<li>如果点落在多个box内，则划分给面积小的物体；</li>
<li>FCOS也使用FPN,也是不同的层预测不同尺寸大小的物体,这样也解决了大小物体重叠分配的问题.</li>
<li><strong>不同层的分支是不共享卷积参数的,retinanet中是共享的</strong>.</li>
<li>其他的fpn参数和retinanet差不多，这里就不解释了。</li>
</ul>
<h3 id="center-ness">center-ness</h3>
<p>因为有了离目标中心越进的点(特征图上的点映射到原图)回归出的边界框的可信度越高的思想,所以这里还加了一个分支预测一个值,这个值就是离中心越近则越大,可视化出来以后就类似于一张热图.相当于这个分支预测一个热图出来,这个图里面可以是有很多目标.</p>
<figure data-type="image" tabindex="1"><img src="https://jzq6520.github.io/post-images/1588176747121.png" alt=""></figure>
<p><img src="https://jzq6520.github.io/post-images/1588177048189.png" alt=""><br>
这里预测类别是和retinanet里面是一样的,用的是focal loss,然后用的是binary crossentropy交叉熵。所以这里最后的类别得分是这个center-ness预测的热图的值乘以分类的值。</p>
<p>其实文章还提高，可以有别的方式替代这个center-ness效果也很好，既然你说离中心很远的预测得到的边界宽不准，那么我们把离中心某个距离半径的圆内的才作为正样本就好了，而不是一个矩阵内的都是正样本。</p>
<p>最后看一下这个网络结构：<br>
<img src="https://jzq6520.github.io/post-images/1588177088021.png" alt=""></p>
<h2 id="实验部分还没看以后有空再看">实验部分还没看，以后有空再看</h2>
<p>已经半夜了。。。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pyvista---(8)体素化显示表面网格和三角网格显示的区别]]></title>
        <id>https://jzq6520.github.io/post/pyvista-8ti-su-hua-xian-shi-biao-mian-wang-ge-surface-mesh</id>
        <link href="https://jzq6520.github.io/post/pyvista-8ti-su-hua-xian-shi-biao-mian-wang-ge-surface-mesh">
        </link>
        <updated>2020-04-03T07:59:56.000Z</updated>
        <content type="html"><![CDATA[<p>之前显示mesh都是用三角网格的方式，其实也可以把每个坐标当做一个像素点，那么点的值就是像素值。<br>
这种显示方法和“统一网格<strong>UniformGrid</strong>”很像，UniformGrid更像是三维的显示一个三维矩阵，就像打印一张二维图像一样，不是mask，但是UniformGrid是不好吧0值变成透明的，而这个显示表明是透明的，体素化显示就可以看做打印3d mask。</p>
<p>下面分别看一下三角表明，体素化的区别：</p>
<h1 id="1-三角网格显示">1. 三角网格显示</h1>
<pre><code># sphinx_gallery_thumbnail_number = 2
from pyvista import examples
import pyvista as pv
import numpy as np

# Load a surface to voxelize
surface = examples.download_foot_bones()
surface

cpos = [(7.656346967151718, -9.802071079151158, -11.021236183314311),
 (0.2224512272564101, -0.4594554282112895, 0.5549738359311297),
 (-0.6279216753504941, -0.7513057097368635, 0.20311105371647392)]

surface.plot(cpos=cpos, opacity=0.75)

</code></pre>
<figure data-type="image" tabindex="1"><img src="https://jzq6520.github.io/post-images/1585901154835.png" alt=""></figure>
<h1 id="2-体素化显示">2. 体素化显示</h1>
<pre><code>voxels = pv.voxelize(surface, density=surface.length/200)

p = pv.Plotter()
p.add_mesh(voxels, color=True, show_edges=True, opacity=0.5)
p.add_mesh(surface, color=&quot;lightblue&quot;, opacity=0.5)
p.show(cpos=cpos)
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://jzq6520.github.io/post-images/1585901505214.png" alt=""></figure>
<h2 id="21-给体素赋值">2.1 给体素赋值</h2>
<p>当然这里也可以是别的值</p>
<pre><code>voxels[&quot;density&quot;] = np.full(voxels.n_cells, 3.65) # g/cc
voxels
voxels.plot(scalars=&quot;density&quot;, cpos=cpos) ## 指定scalars是什么，他会通过字典去索引
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://jzq6520.github.io/post-images/1585901287499.png" alt=""></figure>
<h1 id="链接">链接</h1>
<ul>
<li>https://docs.pyvista.org/examples/01-filter/voxelize.html#sphx-glr-examples-01-filter-voxelize-py</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ Pyvista---(7)pyvista中常用的函数和应用--2]]></title>
        <id>https://jzq6520.github.io/post/pyvista-7pyvista-zhong-chang-yong-de-han-shu-he-ying-yong-2</id>
        <link href="https://jzq6520.github.io/post/pyvista-7pyvista-zhong-chang-yong-de-han-shu-he-ying-yong-2">
        </link>
        <updated>2020-04-03T07:38:57.000Z</updated>
        <content type="html"><![CDATA[<ol>
<li>copy：rot = mesh.copy()</li>
<li>按某个轴旋转：rot.rotate_y(90)</li>
<li>显示的时候设置透明度：p.add_mesh(rot, color=&quot;mintcream&quot;, opacity=0.35, **dargs)</li>
<li>标记一个结构里面包含的另外一个结构的内部的点：select = mesh.select_enclosed_points(rot)</li>
<li>高斯平滑：data.gaussian_smooth(std_dev=2.)</li>
<li>像素化表面Voxelize a Surface Mesh：pv.voxelize(surface, density=surface.length/200)</li>
<li>添加一个标量场，距离的标量场， 该标量场随距边界表面的距离而变化：voxels.compute_implicit_distance(surface, inplace=True)</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pyvista---(6)创建3D矩阵并赋值可视化&创建可视化CT数据]]></title>
        <id>https://jzq6520.github.io/post/pyvista-5chuang-jian-3d-ju-zhen-bing-fu-zhi-ke-shi-hua-chuang-jian-ct-shu-ju</id>
        <link href="https://jzq6520.github.io/post/pyvista-5chuang-jian-3d-ju-zhen-bing-fu-zhi-ke-shi-hua-chuang-jian-ct-shu-ju">
        </link>
        <updated>2020-04-03T05:51:55.000Z</updated>
        <content type="html"><![CDATA[<p>pyvista里面把这种<strong>三维的矩阵</strong>称为“统一网格（Uniform Grid）”，那这个网络里面的值就是矩阵的值。也就是说相当于就是一个矩阵。</p>
<pre><code>values = np.linspace(0, 10, 1000).reshape((20, 5, 10))
values.shape

# 首先类似于新建一个空的矩阵
grid = pv.UniformGrid()

# 然后设置维度，如果想给cell填充数据则维度设置为 矩阵shape + 1，
# 如果是给point填充数据指定为矩阵shape
# 填充cell，颜色就不是渐变的，是每个块一个颜色，正好和ct的数据一样。
grid.dimensions = np.array(values.shape) + 1

# 设置origin和spacing，这两个参数正好和ct的参数一个意思。
grid.origin = (100, 33, 55.6)  # The bottom left corner of the data set
grid.spacing = (1, 5, 2)  # These are the cell sizes along each axis

# 设置（网格）矩阵的值
grid.cell_arrays[&quot;values&quot;] = values.flatten(order=&quot;F&quot;)  # Flatten the array!

# plot
grid.plot(show_edges=True)
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://jzq6520.github.io/post-images/1585893542981.png" alt=""></figure>
<h1 id="显示ct数据">显示ct数据</h1>
<p>下面读取一个ct的数据看看，对ct数据剪切了一下，可以看到里面。<br>
记得显示的适合设置<code>grid.plot(show_edges=False)</code>。<br>
<img src="https://jzq6520.github.io/post-images/1585893792402.png" alt=""></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pyvista---(5)创建三角面]]></title>
        <id>https://jzq6520.github.io/post/pyvista-5pyvista-zhong-chang-yong-de-han-shu-he-ying-yong-2</id>
        <link href="https://jzq6520.github.io/post/pyvista-5pyvista-zhong-chang-yong-de-han-shu-he-ying-yong-2">
        </link>
        <updated>2020-04-03T05:43:03.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-创建三角面triangulated-surface">1. 创建三角面（Triangulated Surface）</h1>
<p>首先是一堆离散的点，然后使用<code>pv.PolyData(points)</code>函数生成三角面。</p>
<pre><code>import pyvista as pv
import numpy as np

# Define a simple Gaussian surface
n = 20
x = np.linspace(-200, 200, num=n) + np.random.uniform(-5, 5, size=n)
y = np.linspace(-200, 200, num=n) + np.random.uniform(-5, 5, size=n)
xx, yy = np.meshgrid(x, y)
A, b = 100, 100
zz = A * np.exp(-0.5 * ((xx / b) ** 2.0 + (yy / b) ** 2.0))

# Get the points as a 2D NumPy array (N by 3)
points = np.c_[xx.reshape(-1), yy.reshape(-1), zz.reshape(-1)]
points[0:5, :]

# simply pass the numpy points to the PolyData constructor
cloud = pv.PolyData(points)
cloud.plot(point_size=15)

</code></pre>
<figure data-type="image" tabindex="1"><img src="https://jzq6520.github.io/post-images/1585892753918.png" alt=""></figure>
<p>然后生成面：</p>
<pre><code>surf = cloud.delaunay_2d()
surf.plot(show_edges=True)
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://jzq6520.github.io/post-images/1585892803751.png" alt=""></figure>
<p>指定alpha=1.0参数可以把多余的点去除：<code>surf = cloud.delaunay_2d(alpha=1.0)</code>,具体示意图就不放了。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pyvista---(4)pyvista中常用的函数和应用]]></title>
        <id>https://jzq6520.github.io/post/pyvista-4pyvista-zhong-chang-yong-de-han-shu-he-ying-yong</id>
        <link href="https://jzq6520.github.io/post/pyvista-4pyvista-zhong-chang-yong-de-han-shu-he-ying-yong">
        </link>
        <updated>2020-04-03T03:03:15.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-多个图类似于matplotlib">1. 多个图，类似于matplotlib</h1>
<pre><code class="language-python">p = pv.Plotter(shape=(3, 3))
p.subplot(0, 0)
</code></pre>
<h1 id="2-指定颜色和平滑阴影">2. 指定颜色和平滑阴影</h1>
<pre><code>supertoroid.plot(color=&quot;tan&quot;, smooth_shading=True)
</code></pre>
<h1 id="3-创建点云">3. 创建点云</h1>
<pre><code class="language-python">import pyvista as pv
import numpy as np
## 生成一组点云的坐标，然后构建点云的mesh
points = np.random.rand(30000, 3)
point_cloud = pv.PolyData(points)
print np.allclose(points, point_cloud.points)#检测是否一致
# 画点云
point_cloud.plot(eye_dome_lighting=True)
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://jzq6520.github.io/post-images/1585884475887.png" alt=""></figure>
<h2 id="31-给点云赋值">3.1 给点云赋值</h2>
<pre><code class="language-python">## 给点云赋值，这里就把z轴坐标的值赋值给点云
data = points[:,-1]
point_cloud[&quot;value&quot;] = data
point_cloud.plot(render_points_as_spheres=True)
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://jzq6520.github.io/post-images/1585884520313.png" alt=""></figure>
<h2 id="32-画向量把向量的值存在点云中">3.2 画向量,把向量的值存在点云中</h2>
<p>因为mesh个一给点赋很多的值，通过字典的形式，只需要个数对的上，还有就是mesh中点的顺序要和值的存储顺序一样。</p>
<pre><code>def compute_vectors(mesh):
    origin = mesh.center
    vectors = mesh.points - origin
    vectors = vectors / np.linalg.norm(vectors, axis=1)[:, None]
    return vectors

vectors = compute_vectors(point_cloud)
point_cloud['vectors'] = vectors
arrows = point_cloud.glyph(orient='vectors', scale=False, factor=0.15,) #通过这个函数构建箭头
# Display the arrows
plotter = pv.Plotter()
plotter.add_mesh(point_cloud, color='maroon', point_size=10.,
                 render_points_as_spheres=True)
plotter.add_mesh(arrows, color='lightblue')
# plotter.add_point_labels([point_cloud.center,], ['Center',],
#                          point_color='yellow', point_size=20)
plotter.show_grid()
plotter.show()

</code></pre>
<figure data-type="image" tabindex="3"><img src="https://jzq6520.github.io/post-images/1585884809052.png" alt=""></figure>
<h1 id="4-画多面的图并不是封闭">4. 画多面的图，并不是封闭</h1>
<pre><code>import pyvista as pv
# mesh points
vertices = np.array([[0, 0, 0],
                     [1, 0, 0],
                     [1, 1, 0],
                     [0, 1, 0],
                     [0.5, 0.5, -1]])

# mesh faces,这个还不知道是什么意思，怎么定义？
faces = np.hstack([[4, 0, 1, 2, 3],  # square
                   [3, 0, 1, 4],     # triangle
                   [3, 1, 2, 4]])    # triangle

surf = pv.PolyData(vertices, faces)
surf.cell_arrays['scalars'] = np.arange(3)
# plot each face with a different color
# surf.plot(scalars=np.arange(3), cpos=[-1, 1, 0.5])

p = pv.Plotter() ## 建一个普通画板
# p = pv.BackgroundPlotter() ## 建一个交互式画板
p.camera_position = [-1, 1, 0.5]
p.add_mesh(surf)
p.show()
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://jzq6520.github.io/post-images/1585885445640.png" alt=""></figure>
<h1 id="5-画线条">5. 画线条</h1>
<p>https://docs.pyvista.org/examples/00-load/create-spline.html</p>
<pre><code class="language-python">def make_points():
    &quot;&quot;&quot;Helper to make XYZ points&quot;&quot;&quot;
    theta = np.linspace(-4 * np.pi, 4 * np.pi, 100)
    z = np.linspace(-2, 2, 100)
    r = z**2 + 1
    x = r * np.sin(theta)
    y = r * np.cos(theta)
    return np.column_stack((x, y, z))

points = make_points()

def polyline_from_points(points):
    poly = pv.PolyData()
    poly.points = points
    the_cell = np.arange(0, len(points), dtype=np.int)
    the_cell = np.insert(the_cell, 0, len(points))
    poly.lines = the_cell
    return poly

polyline = polyline_from_points(points)
polyline[&quot;scalars&quot;] = np.arange(polyline.n_points)
tube = polyline.tube(radius=0.1)
tube.plot(smooth_shading=True)
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://jzq6520.github.io/post-images/1585885657835.png" alt=""></figure>
<h2 id="51-让线条更加平滑">5.1 让线条更加平滑</h2>
<p>通过插值</p>
<pre><code># Create spline with 1000 interpolation points
spline = pv.Spline(points, 1000)

# add scalars to spline and plot it
spline[&quot;scalars&quot;] = np.arange(spline.n_points)
tube = spline.tube(radius=0.1)
tube.plot(smooth_shading=True)
</code></pre>
<figure data-type="image" tabindex="6"><img src="https://jzq6520.github.io/post-images/1585885783913.png" alt=""></figure>
<h2 id="52-画中心线细线">5.2 画中心线/细线</h2>
<p>样条线也可以绘制为普通线</p>
<pre><code># generate same spline with 400 interpolation points
spline = pv.Spline(points, 400)

# plot without scalars
spline.plot(line_width=4, color=&quot;k&quot;)
</code></pre>
<figure data-type="image" tabindex="7"><img src="https://jzq6520.github.io/post-images/1585885858134.png" alt=""></figure>
<h1 id="6-绘制表明曲面三维mask">6. 绘制表明，曲面，三维mask</h1>
<p>https://docs.pyvista.org/examples/00-load/create-structured-surface.html</p>
<p>首先构建一个numpy的meshgrid，然后用pyvista画。</p>
<pre><code class="language-python">import pyvista as pv
from pyvista import examples
import numpy as np

x = np.arange(-10, 10, 0.25)
y = np.arange(-10, 10, 0.25)
x, y = np.meshgrid(x, y)
r = np.sqrt(x ** 2 + y ** 2)
z = np.sin(r)

grid = pv.StructuredGrid(x, y, z)
grid.plot()

</code></pre>
<figure data-type="image" tabindex="8"><img src="https://jzq6520.github.io/post-images/1585886015467.png" alt=""></figure>
<p>访问其中的点的值：</p>
<pre><code>grid.points
</code></pre>
<h2 id="61-绘制平均曲率">6.1 绘制平均曲率</h2>
<pre><code># Plot mean curvature as well
grid.plot_curvature(clim=[-1, 1])
</code></pre>
<h1 id="7-创建一个空的grid结构然后设置坐标">7 创建一个空的grid结构，然后设置坐标</h1>
<p>坐标的顺序是对的才可以，不然画出来会是乱的。</p>
<pre><code>points = np.random.rand(30000, 3)

mesh = pv.StructuredGrid()
# Set the coordinates from the numpy array
mesh.points = points
# set the dimensions
mesh.dimensions = [29, 32, 1]

# and then inspect it!
mesh.plot(show_edges=True, show_grid=True, cpos=&quot;xy&quot;)
</code></pre>
<p>下图就是乱的，因为坐标是随机生成的，坐标的顺序是混乱的。<br>
<img src="https://jzq6520.github.io/post-images/1585891666700.png" alt=""></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pyvista---(3)pyvista中mesh的构造和画图]]></title>
        <id>https://jzq6520.github.io/post/pyvista-3pyvista-zhong-mesh-de-gou-zao-he-hua-tu</id>
        <link href="https://jzq6520.github.io/post/pyvista-3pyvista-zhong-mesh-de-gou-zao-he-hua-tu">
        </link>
        <updated>2020-04-03T01:31:56.000Z</updated>
        <content type="html"><![CDATA[<h1 id="mesh的构造">mesh的构造</h1>
<ol>
<li>cell的数量：mesh.n_cells</li>
<li>points的数量：mesh.n_points</li>
<li>mesh的中心：mesh.center</li>
<li>mesh的点：mesh.points</li>
<li>mesh中包含的矩阵：mesh.point_arrays</li>
<li>查看mesh的信息：print mesh</li>
<li>访问mesh中矩阵的值：通过字典的方式访问
<ol>
<li>访问point的值：mesh.point_arrays['new_points']</li>
<li>访问cell的值：mesh.cell_arrays['new_points']</li>
</ol>
</li>
<li>给mesh赋值：
<ol>
<li>给point赋值：mesh.point_arrays['new_points'] = np.zeros(mesh.n_points)</li>
<li>给cell赋值：mesh.cell_arrays['new_points'] = np.zeros(mesh.n_cells)</li>
</ol>
</li>
<li>如果是结构化的矩阵，获得mesh的值的维度：mesh.dimensions</li>
</ol>
<h1 id="画mesh">画mesh</h1>
<p>有两种方法画mesh</p>
<h2 id="第一种">第一种</h2>
<p>直接画。</p>
<pre><code>import pyvista as pv
from pyvista import examples

mesh = examples.load_airplane()
mesh.plot(screenshot='airplane.png')
</code></pre>
<h2 id="第二种">第二种</h2>
<p>指定更多参数的画：<br>
先通过<code>pv.Plotter()</code>新建一个渲染窗口，然后通过<code>add_mesh</code>增加mesh。</p>
<pre><code class="language-python">plotter = pv.Plotter()    # instantiate the plotter
plotter.add_mesh(mesh)    # add a mesh to the scene
cpos = plotter.show()     # show the rendering window
</code></pre>
<p>请注意，该show方法将返回渲染窗口上次使用的相机位置，以备您选择相机位置并在以后再次使用时使用。</p>
<p>然后，您可以使用此缓存的摄像机进行其他打印，而不必与打印窗口手动交互：</p>
<pre><code class="language-python">plotter = pv.Plotter(off_screen=True)
plotter.add_mesh(mesh, color='tan')
plotter.camera_position = cpos
plotter.show(screenshot='airplane.png') ## 保存成图片
</code></pre>
<h2 id="可交互的窗口">可交互的窗口</h2>
<ul>
<li>pyvista.Plotter：标准绘图仪，它将代码暂停直到关闭</li>
<li>pyvista.BackgroundPlotter：创建一个交互式的渲染窗口，并且不暂停代码执行</li>
</ul>
<h2 id="导出mesh保存成vtk">导出mesh，保存成vtk</h2>
<p>可以使用.save() 直接绑定到这些对象的方法将任何PyVista网格对象保存为VTK文件格式。例如，上面使用的网格可以保存为：</p>
<pre><code>mesh.save(&quot;mesh.vtk&quot;)
</code></pre>
<h1 id="例子">例子</h1>
<pre><code class="language-python">&gt;&gt;&gt; mesh = examples.load_airplane()
&gt;&gt;&gt; # cell的数量
&gt;&gt;&gt; mesh.n_cells
2452
&gt;&gt;&gt; # point的数量
&gt;&gt;&gt; mesh.n_points
1335
&gt;&gt;&gt; # What about scalar arrays? Are there any?
&gt;&gt;&gt; mesh.n_arrays
0
&gt;&gt;&gt; # What are the mesh bounds?
&gt;&gt;&gt; mesh.bounds
[139.06100463867188, 1654.9300537109375, 32.09429931640625, 1319.949951171875, -17.741199493408203, 282.1300048828125]
&gt;&gt;&gt; # mesh的中心
&gt;&gt;&gt; mesh.center
[896.9955291748047, 676.0221252441406, 132.19440269470215]
# 点
the_pts = mesh.points
array([[896.994 ,  48.7601,  82.2656],
       [906.593 ,  48.7601,  80.7452],
       [907.539 ,  55.4902,  83.6581],
       [896.994 ,  55.4902,  85.3283],
       [896.994 ,  42.8477,  77.825 ]], dtype=float32)

</code></pre>
<h2 id="point_arrays">point_arrays</h2>
<pre><code class="language-python">mesh = examples.load_uniform()
## 获得值
arr = mesh.point_arrays['Spatial Point Data']
print mesh #查看mesh信息

output：
UniformGrid (0x12c9a9328)
  N Cells:	729
  N Points:	1000
  X Bounds:	0.000e+00, 9.000e+00
  Y Bounds:	0.000e+00, 9.000e+00
  Z Bounds:	0.000e+00, 9.000e+00
  Dimensions:	10, 10, 10
  Spacing:	1.000e+00, 1.000e+00, 1.000e+00
  N Arrays:	2

# mesh.dimensions
mesh = examples.load_uniform()
mesh.dimensions
output：
[10, 10, 10]
</code></pre>
<p>mesh的值是存储成一维的，所以如果想转换成原来的三维矩阵的话，就需要按照mesh.dimensions 将arr矩阵转换成矩阵。这样其实就是一个矩阵了，因为numpy矩阵本身就是这样。</p>
<h2 id="如果是unstructuredgrid则没有meshdimensions">如果是'UnstructuredGrid'则没有mesh.dimensions</h2>
<p>访问的话就会报错：</p>
<pre><code>AttributeError: 'UnstructuredGrid' object has no attribute 'dimensions'
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pyvista---(2)pyvista中的mesh定义]]></title>
        <id>https://jzq6520.github.io/post/pyvista-1pyvista-zhong-de-mesh-ding-yi</id>
        <link href="https://jzq6520.github.io/post/pyvista-1pyvista-zhong-de-mesh-ding-yi">
        </link>
        <updated>2020-04-02T08:32:01.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>为了简化数据表示的复杂度，在pyvista中，mesh可以表示面，也可以表示体素。</li>
<li>pyvista里面的所有数据都有节点（node），节点是网格的顶点，由XYZ坐标表示，即使是二维数据也是要有XYZ坐标。</li>
<li>数据也可以是只包含顶点，比如点云（point cloud），点云是一群点。</li>
</ul>
<h1 id="0-mesh-三要素">0 mesh 三要素</h1>
<ul>
<li>顶点（node）</li>
<li>格子（cell)</li>
<li>值（attributes）:可以是顶点的值也可以是格子的值，如果设置顶点的值那么颜色就是渐变的，设置格子的值颜色就是不渐变的。</li>
</ul>
<h2 id="1-mesh中的顶点">1 mesh中的顶点</h2>
<p>下面以三个例子说明</p>
<h3 id="11-点云">1.1 点云</h3>
<ul>
<li>可以用<code>pyvista.PolyData</code>来创建点云，也就是创建一个包含点的数据结构，可以是二维的也可以是三维的，然后这个数据是可以用来被可视化的。</li>
<li>用numpy生成一堆点云的坐标，然后转为用vista可视化出来。</li>
</ul>
<pre><code class="language-python">import numpy as np
import pyvista as pv

nodes = np.random.rand(100, 3)
mesh = pv.PolyData(nodes)
mesh.plot(point_size=10, screenshot='random_nodes.png')
</code></pre>
<p>结果：<br>
<img src="https://jzq6520.github.io/post-images/1585817022539.png" alt=""></p>
<h3 id="12-网格gridded-mesh三维数组">1.2 网格（gridded mesh），三维数组</h3>
<pre><code class="language-python">import pyvista as pv
from pyvista import examples
mesh = examples.load_hexbeam()

p = pv.Plotter() ## 建一个画板
# 然后在画板上画图
p.add_mesh(mesh, show_edges=True, color='white')
p.add_mesh(pv.PolyData(mesh.points), color='red', point_size=10, render_points_as_spheres=True)
## 相机位置
p.camera_position = [(6.20, 3.00, 7.50),
                 (0.16, 0.13, 2.65),
                 (-0.28, 0.94, -0.21)]
p.show(screenshot='beam_nodes.png')
</code></pre>
<p>结果：<br>
<img src="https://jzq6520.github.io/post-images/1585817823046.png" alt=""></p>
<h3 id="13-三角表面兔子">1.3 三角表面，兔子</h3>
<pre><code class="language-python">mesh = examples.download_bunny_coarse()

p = pv.Plotter()
p.add_mesh(mesh, show_edges=True, color='white')
p.add_mesh(pv.PolyData(mesh.points), color='red',
       point_size=10, render_points_as_spheres=True)
p.camera_position = [(0.02, 0.30, 0.73),
                 (0.02, 0.03, -0.022),
                 (-0.03, 0.94, -0.34)]
p.show(screenshot='bunny_nodes.png')
</code></pre>
<p>结果：<br>
<img src="https://jzq6520.github.io/post-images/1585817927157.png" alt=""></p>
<h2 id="2-mesh中的-cell单元小格子">2 mesh中的 cell（单元），小格子</h2>
<ul>
<li>如果了解医学图像处理的话，ct中的一个体素就是一个cell。</li>
<li>当然，单元不仅限于体素，它们可以是三个节点之间的三角形，两个节点之间的线，甚至单个节点也可以是其自己的单元（但这是特例）。</li>
</ul>
<p>如图所示：<br>
<img src="https://jzq6520.github.io/post-images/1585818259021.png" alt=""></p>
<p>在前面的代码上加上这句话即可画出上图：</p>
<pre><code class="language-python">p.add_mesh(mesh.extract_cells(mesh.n_cells-1),
           color='pink', edge_color='blue',
           line_width=5, show_edges=True)
</code></pre>
<h2 id="3-mesh中的属性attributes颜色">3 mesh中的属性（attributes），颜色</h2>
<ul>
<li>给每个顶点赋值，所以他的颜色是渐变的，如果给cell赋值，那么每个格子的颜色就是一样的。</li>
<li>之前说的顶点是坐标点，那这个属性就是这个坐标点的值。简单来说顶点是矩阵的坐标，属性就是矩阵里面的值。那么值被可视化出来就是灰度了。<strong>毕竟在图像中矩阵的值就表示灰度值</strong>。</li>
<li>可以通过<code>.point_arrays</code>或<code>.cell_arrays</code>方法来给mesh赋值。值可以是point的或是cell的，通过这个两个方法。这两个方法是一个字典。</li>
<li>point数据是指存在于网格的每个节点上的值的数组（标量，向量等）。该数组的顺序至关重要！属性数组中的每个元素必须对应于网格中的节点或单元。</li>
</ul>
<pre><code class="language-python">import pyvista as pv
from pyvista import examples
mesh = examples.load_hexbeam()
camera_position = [(6.20, 3.00, 7.50),
                 (0.16, 0.13, 2.65),
                 (-0.28, 0.94, -0.21)]
# 这里是给每个顶点赋值，所以他的颜色是渐变的，如果给cell赋值，那么每个格子的颜色就是一样的。
mesh.point_arrays['my point values'] = np.arange(mesh.n_points)

mesh.plot(scalars='my point values', cpos=camera_position,
          show_edges=True, screenshot='beam_point_data.png')
</code></pre>
<ul>
<li>这里是给每个顶点赋值，所以他的颜色是渐变的，如果给cell赋值，那么每个格子的颜色就是一样的。<br>
<img src="https://jzq6520.github.io/post-images/1585819280887.png" alt=""></li>
</ul>
<h4 id="给格子cell赋值">给格子（cell）赋值</h4>
<pre><code class="language-python">mesh.cell_arrays['my cell values'] = np.arange(mesh.n_cells)
mesh.plot(scalars='my cell values', cpos=bcpos,
          show_edges=True, screenshot='beam_cell_data.png')
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://jzq6520.github.io/post-images/1585819438010.png" alt=""></figure>
<h2 id="链接">链接</h2>
<ul>
<li>https://docs.pyvista.org/getting-started/what-is-a-mesh.html</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pyvista---(1)一种强大的三维可视化工具]]></title>
        <id>https://jzq6520.github.io/post/pyvista-1yi-chong-qiang-da-de-san-wei-ke-shi-hua-gong-ju</id>
        <link href="https://jzq6520.github.io/post/pyvista-1yi-chong-qiang-da-de-san-wei-ke-shi-hua-gong-ju">
        </link>
        <updated>2020-04-02T07:29:22.000Z</updated>
        <content type="html"><![CDATA[<h1 id="pyvista是什么">Pyvista是什么</h1>
<p>他是VTK的python高级API，官方称为：<em>“VTK for humans”: a high-level API to the Visualization Toolkit (VTK)</em>。</p>
<p>确实，原始的vtk的python接口简直是反人类，而且文档极其难看。</p>
<h2 id="简介">简介</h2>
<p>PyVista是…</p>
<ul>
<li>可视化工具包（VTK）的高级API</li>
<li>mesh data structures and filtering methods for spatial datasets</li>
<li>让3D绘图变得简单，可用于大型/复杂数据几何</li>
</ul>
<p>PyVista（以前是vtki）是Visualization Toolkit（VTK）的帮助程序模块，它通过NumPy和直接数组访问采用了与VTK接口不同的方法。 该软件包提供了Pythonic的，有据可查的界面，可显示VTK强大的可视化后端，以促进空间参考数据集的快速原型制作，分析和可视化集成。</p>
<p>该模块可用于演示文稿和研究论文的科学绘图，以及其他与网格相关的Python模块的支持模块。</p>
<h2 id="如何安装">如何安装</h2>
<pre><code>pip install pyvista
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[目标检测--RetinaNet代码实现的细节]]></title>
        <id>https://jzq6520.github.io/post/mu-biao-jian-ce-retinanet-dai-ma-shi-xian-de-xi-jie-wen-ti</id>
        <link href="https://jzq6520.github.io/post/mu-biao-jian-ce-retinanet-dai-ma-shi-xian-de-xi-jie-wen-ti">
        </link>
        <updated>2019-11-26T14:13:37.000Z</updated>
        <content type="html"><![CDATA[<ol>
<li>网络：
<ol>
<li>除了backbone部分，其他的fpn、分类subnet和回归subnet都不加bn；</li>
<li>fpn的部分不加激活，回归和分类subnet加relu激活，最后的回归不加激活；</li>
<li>p6到p7要做激活；</li>
</ol>
</li>
<li>loss：
<ol>
<li>回归只计算正样本的loss，<strong>且除以正样本的个数</strong>。</li>
<li>分类只计算正样本和负样本的loss，并且也是<strong>除以正样本的个数</strong>，而不是除以正负样本的。</li>
</ol>
</li>
<li><strong>回归subnet是不共享参数的，分类subnet共享参数</strong>；</li>
<li>最后预测的时候，对预测的所有概率进行排序，然后取前1000个bbox，然后卡0.05的阈值，最后做nms，<strong>nms的阈值是0.5</strong>.</li>
<li>分类的最后一个conv的bias初始化为<code>-log((1-0.01)/0.01)</code>,其他照样初始化为0，子网络其他部分卷积核进行标准差为0.01的高斯初始化，bias为0初始化。</li>
<li>除了backbone部分使用迁移学习，<strong>其他conv参数的初始化都使用，均值为0.，标准差为0.01的高斯分布</strong>，不然有一定概率出现模型不收敛，然后loss爆炸。</li>
<li></li>
</ol>
<h2 id="keras中是直接回归两个角的坐标">keras中是直接回归两个角的坐标</h2>
<p>其实也是可以回归中心点和宽高的。<br>
如下所示，直接回归角点坐标的一个变换，而不是中心点和宽高：</p>
<pre><code class="language-python">targets_dx1 = (gt_boxes[:, 0] - anchors[:, 0]) / anchor_widths
targets_dy1 = (gt_boxes[:, 1] - anchors[:, 1]) / anchor_heights
targets_dx2 = (gt_boxes[:, 2] - anchors[:, 2]) / anchor_widths
targets_dy2 = (gt_boxes[:, 3] - anchors[:, 3]) / anchor_heights
</code></pre>
<p>然后最后的网络回归的数值还要再在之前的上面除以一个0.2</p>
<pre><code>if mean is None:
        mean = np.array([0, 0, 0, 0])
if std is None:
    std = np.array([0.2, 0.2, 0.2, 0.2])
targets = np.stack((targets_dx1, targets_dy1, targets_dx2, targets_dy2))
targets = targets.T

targets = (targets - mean) / std
</code></pre>
<h2 id="子网络subnet">子网络subnet</h2>
<p>代码：https://github.com/fizyr/keras-retinanet</p>
<pre><code class="language-python">## 回归的subnet
options = {
        'kernel_size'        : 3,
        'strides'            : 1,
        'padding'            : 'same',
        'kernel_initializer' : keras.initializers.normal(mean=0.0, stddev=0.01, seed=None),
        'bias_initializer'   : 'zeros'}
for i in range(4):
        outputs = keras.layers.Conv2D(
            filters=regression_feature_size,
            activation='relu',
            name='pyramid_regression_{}'.format(i),
            **options
        )(outputs)

    outputs = keras.layers.Conv2D(num_anchors * num_values, name='pyramid_regression', **options)(outputs)

## 分类的subnet
options = {
        'kernel_size' : 3,
        'strides'     : 1,
        'padding'     : 'same',
    }
for i in range(4):
        outputs = keras.layers.Conv2D(
            filters=classification_feature_size,
            activation='relu',
            name='pyramid_classification_{}'.format(i),
            kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None),
            bias_initializer='zeros',
            **options
        )(outputs)

    outputs = keras.layers.Conv2D(
        filters=num_classes * num_anchors,
        kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None),
        bias_initializer=initializers.PriorProbability(probability=prior_probability),
        name='pyramid_classification',
        **options
    )(outputs)
</code></pre>
<h2 id="fpn">fpn</h2>
<p>代码：https://github.com/fizyr/keras-retinanet</p>
<pre><code class="language-python">def __create_pyramid_features(C3, C4, C5, feature_size=256):
  
    # upsample C5 to get P5 from the FPN paper
    P5           = keras.layers.Conv2D(feature_size, kernel_size=1, strides=1, padding='same', name='C5_reduced')(C5)
    P5_upsampled = layers.UpsampleLike(name='P5_upsampled')([P5, C4])
    P5           = keras.layers.Conv2D(feature_size, kernel_size=3, strides=1, padding='same', name='P5')(P5)

    # add P5 elementwise to C4
    P4           = keras.layers.Conv2D(feature_size, kernel_size=1, strides=1, padding='same', name='C4_reduced')(C4)
    P4           = keras.layers.Add(name='P4_merged')([P5_upsampled, P4])
    P4_upsampled = layers.UpsampleLike(name='P4_upsampled')([P4, C3])
    P4           = keras.layers.Conv2D(feature_size, kernel_size=3, strides=1, padding='same', name='P4')(P4)

    # add P4 elementwise to C3
    P3 = keras.layers.Conv2D(feature_size, kernel_size=1, strides=1, padding='same', name='C3_reduced')(C3)
    P3 = keras.layers.Add(name='P3_merged')([P4_upsampled, P3])
    P3 = keras.layers.Conv2D(feature_size, kernel_size=3, strides=1, padding='same', name='P3')(P3)

    # &quot;P6 is obtained via a 3x3 stride-2 conv on C5&quot;
    P6 = keras.layers.Conv2D(feature_size, kernel_size=3, strides=2, padding='same', name='P6')(C5)

    # &quot;P7 is computed by applying ReLU followed by a 3x3 stride-2 conv on P6&quot;
    P7 = keras.layers.Activation('relu', name='C6_relu')(P6)
    P7 = keras.layers.Conv2D(feature_size, kernel_size=3, strides=2, padding='same', name='P7')(P7)

    return [P3, P4, P5, P6, P7]
</code></pre>
<h2 id="loss">loss</h2>
<p>代码：https://github.com/fizyr/keras-retinanet</p>
<p>anchor_state:一个向量，也可以单独传入，-1表示不属于正负样本，是被忽略的，0表示负样本，1表示正样本。</p>
<pre><code class="language-python">
def focal(alpha=0.25, gamma=2.0):
    &quot;&quot;&quot; Create a functor for computing the focal loss.

    Args
        alpha: Scale the focal weight with alpha.
        gamma: Take the power of the focal weight with gamma.

    Returns
        A functor that computes the focal loss using the alpha and gamma.
    &quot;&quot;&quot;
    def _focal(y_true, y_pred):
        &quot;&quot;&quot; Compute the focal loss given the target tensor and the predicted tensor.

        As defined in https://arxiv.org/abs/1708.02002

        Args
            y_true: Tensor of target data from the generator with shape (B, N, num_classes).
            y_pred: Tensor of predicted data from the network with shape (B, N, num_classes).

        Returns
            The focal loss of y_pred w.r.t. y_true.
        &quot;&quot;&quot;
        labels         = y_true[:, :, :-1]
        anchor_state   = y_true[:, :, -1]  # -1 for ignore, 0 for background, 1 for object
        classification = y_pred

        # filter out &quot;ignore&quot; anchors
        indices        = backend.where(keras.backend.not_equal(anchor_state, -1))
        labels         = backend.gather_nd(labels, indices)
        classification = backend.gather_nd(classification, indices)

        # compute the focal loss
        alpha_factor = keras.backend.ones_like(labels) * alpha
        alpha_factor = backend.where(keras.backend.equal(labels, 1), alpha_factor, 1 - alpha_factor)
        focal_weight = backend.where(keras.backend.equal(labels, 1), 1 - classification, classification)
        focal_weight = alpha_factor * focal_weight ** gamma

        cls_loss = focal_weight * keras.backend.binary_crossentropy(labels, classification)

        # compute the normalizer: the number of positive anchors
        normalizer = backend.where(keras.backend.equal(anchor_state, 1))
        normalizer = keras.backend.cast(keras.backend.shape(normalizer)[0], keras.backend.floatx())
        normalizer = keras.backend.maximum(keras.backend.cast_to_floatx(1.0), normalizer)

        return keras.backend.sum(cls_loss) / normalizer

    return _focal


def smooth_l1(sigma=3.0):
    &quot;&quot;&quot; Create a smooth L1 loss functor.

    Args
        sigma: This argument defines the point where the loss changes from L2 to L1.

    Returns
        A functor for computing the smooth L1 loss given target data and predicted data.
    &quot;&quot;&quot;
    sigma_squared = sigma ** 2

    def _smooth_l1(y_true, y_pred):
        &quot;&quot;&quot; Compute the smooth L1 loss of y_pred w.r.t. y_true.

        Args
            y_true: Tensor from the generator of shape (B, N, 5). The last value for each box is the state of the anchor (ignore, negative, positive).
            y_pred: Tensor from the network of shape (B, N, 4).

        Returns
            The smooth L1 loss of y_pred w.r.t. y_true.
        &quot;&quot;&quot;
        # separate target and state
        regression        = y_pred
        regression_target = y_true[:, :, :-1]
        anchor_state      = y_true[:, :, -1]

        # filter out &quot;ignore&quot; anchors
        indices           = backend.where(keras.backend.equal(anchor_state, 1))
        regression        = backend.gather_nd(regression, indices)
        regression_target = backend.gather_nd(regression_target, indices)

        # compute smooth L1 loss
        # f(x) = 0.5 * (sigma * x)^2          if |x| &lt; 1 / sigma / sigma
        #        |x| - 0.5 / sigma / sigma    otherwise
        regression_diff = regression - regression_target
        regression_diff = keras.backend.abs(regression_diff)
        regression_loss = backend.where(
            keras.backend.less(regression_diff, 1.0 / sigma_squared),
            0.5 * sigma_squared * keras.backend.pow(regression_diff, 2),
            regression_diff - 0.5 / sigma_squared
        )

        # compute the normalizer: the number of positive anchors
        normalizer = keras.backend.maximum(1, keras.backend.shape(indices)[0])
        normalizer = keras.backend.cast(normalizer, dtype=keras.backend.floatx())
        return keras.backend.sum(regression_loss) / normalizer

    return _smooth_l1
</code></pre>
<h2 id="引用">引用</h2>
<ul>
<li>代码：https://github.com/fizyr/keras-retinanet</li>
<li>https://medium.com/@14prakash/the-intuition-behind-retinanet-eb636755607d</li>
</ul>
]]></content>
    </entry>
</feed>